# -*- coding: utf-8 -*-
"""Untitled9.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Al_j5QrHA9SDv-mVCeUJu3D1uI7G43Wp
"""

# This delta project will help scientists determine where to focus efforts
# on locations where deltas will very closely sink

from numpy.lib.function_base import median
import math
from google.colab import files
import os
import tensorflow as tf

import numpy as np
import tifffile as tiff
from google.colab.patches import cv2_imshow
import cv2
from pandas import datetime

from pandas import DataFrame
import statsmodels.tsa.exponential_smoothing 

from statsmodels.tsa.arima_model import ARIMA

import pandas

files.upload()



!unzip PreDeltaX_L3_AVIRIS_Biomass_1821.zip

!unzip DeltaX_Sonar_Bathymetry_2085.zip

!unzip PreDeltaX_Water_Level_Data_1801.zip

!unzip DeltaX_Turbidity_Data_V3_2113.zip

!unzip DeltaX_Sediment_Grain_Size_2061.zip

for file in os.listdir("/content/DeltaX_Sonar_Bathymetry_2085/data/"):
  if file.endswith("csv"):
    file.find("velocity")
    print(file)
    file = "DeltaX_Sonar_Bathymetry_2085/data/" + file
    fileu = pandas.DataFrame(np.array(pandas.read_csv(file
          )))
    fileu[11] = fileu[2] + "-" + fileu[3]
    averadepth = fileu[8].mean()
    waterdepth2 = pandas.DataFrame(data = [[file[34:], averadepth, fileu[4], fileu[5], fileu[2]]])
    waterdepth10 = pandas.DataFrame(data = [["one", "two", "three", "fourth", "fifth"]])
    waterdepth17 = waterdepth17
    r = 1
    # get average of each file for water depth and add color for vulnerable sink
    waterdepth17 = pandas.concat([waterdepth17, waterdepth2, waterdepth10])
    for file in os.listdir("/content/DeltaX_Sediment_Grain_Size_2061/data"):
      if file.endswith("1.csv") and r == 1:
        fileu[15] = fileu[2]
        r += 1
    for i in fileu[8]:
      s = 0
      if fileu[8][0] or i > averadepth / 2:
        fileu[15][s] = "green"
      elif fileu[8][0] or i < averadepth / 2:
        fileu[15][s] = "red"
      s = 1 + s
    fileu.to_csv(file[34:] + "total")
    waterdepth17.to_csv("totaldepths.csv")

# We rename the file to totaldepths_final.csv for running stats

# make datetime for timeseries data

def stre(s):
  return datetime.strptime(s, '%Y-%m-%d')

# use ARIMA stats to forecast the future water depths

series = pandas.read_csv("totaldepths_final.csv", header = 0, parse_dates = ["time"], index_col = 0, date_parser = stre)
series["11"] = series["2"] + " " + series["3"]
print(series)
series2 = series.drop(columns = ["0", "1", "6", "3", "4", "5", "2", "7", "15", "10", "9"])
prediction = ARIMA(np.asarray(series2["8"]), order = (5, 1, 0))
trasfit = prediction.fit(disp = 0)
residuals = DataFrame(trasfit.resid)
output = trasfit.forecast(steps = 72)
yhat = output[0]
se = list()
se.append(yhat)
print(file)
se = pandas.DataFrame(se)
series2["11"][-1]
se.to_csv("data_forecasts")